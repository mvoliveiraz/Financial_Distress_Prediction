{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fc540f08-6695-4196-af76-3aa0a236edb2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install seaborn\n",
    "%pip install xgboost\n",
    "%pip install lightgbm\n",
    "%pip install imbalanced-learn\n",
    "%pip install feature-engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eec3d44a-9def-4f0f-8ebd-3930644ff654",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%pip install pandas==1.5.3\n",
    "# --- Bibliotecas para Manipulação de Dados ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- Bibliotecas para Visualização ---\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Ferramentas do Scikit-learn para Pré-processamento e Pipelines ---\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline # O pipeline padrão do Scikit-learn\n",
    "\n",
    "# --- NOVAS: Bibliotecas para Modelagem e Balanceamento ---\n",
    "\n",
    "# Para balanceamento de classes com SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline # Usamos um alias para não confundir com o pipeline do sklearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Para o modelo RandomForest (que já usamos)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Para o modelo LightGBM\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Para o modelo XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "# --- Ferramentas para Avaliação do Modelo ---\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, precision_recall_curve\n",
    "\n",
    "# --- Configurações Adicionais (Opcional) ---\n",
    "# Para ignorar avisos que não são críticos\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Para ver todas as colunas de um DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"Bibliotecas importadas com sucesso!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3984a4af-d1e3-43d7-a6e4-9c953489576a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cs-training.csv')\n",
    "df_2 = pd.read_csv('cs-test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "38fa4353-60ae-4fe9-9260-8594383b9611",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_train = df.copy()\n",
    "\n",
    "df_train['BaLim_ratio'] = df_train['RevolvingUtilizationOfUnsecuredLines'].clip(upper=1.2)\n",
    "\n",
    "df_train['age_2'] = np.where(df_train['age'] == 0, 20, df_train['age'])\n",
    "\n",
    "income_capped = df_train['MonthlyIncome'].clip(upper=23300)\n",
    "# Depois, aplicamos a transformação de log\n",
    "df_train['Income_log'] = np.log(income_capped + 10)\n",
    "        \n",
    "df_train['Income_bool'] = np.where(df_train['MonthlyIncome'] > 0, 1, 0)\n",
    "\n",
    "df_train['Dep'] = df_train['NumberOfDependents'].clip(upper=2)\n",
    "\n",
    "df_train['D_Ratio'] = np.where(df_train['DebtRatio'] >= 1200, 6, np.where(df_train['DebtRatio'] > 4, 5, df_train['DebtRatio']))\n",
    "        \n",
    "df_train['OCLAL'] = np.log1p(df_train['NumberOfOpenCreditLinesAndLoans'])\n",
    "\n",
    "df_train['REOL'] = df_train['NumberRealEstateLoansOrLines'].clip(upper=5)\n",
    "\n",
    "df_train['Num_30-59'] = df_train['NumberOfTime30-59DaysPastDueNotWorse'].clip(upper=3)\n",
    "\n",
    "df_train['Num_60-89'] = df_train['NumberOfTime60-89DaysPastDueNotWorse'].clip(upper=2)\n",
    "\n",
    "df_train['Num_90'] = df_train['NumberOfTimes90DaysLate'].clip(upper=2)\n",
    "\n",
    "df_train['Income_log_sq'] = df_train['Income_log']**2\n",
    "df_train['Income_log_cub'] = df_train['Income_log']**3\n",
    "df_train['D_Ratio_sq'] = df_train['D_Ratio']**2 \n",
    "\n",
    "df_treino_final = df_train.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2e026a9-b78b-45a8-ab4d-325388fedc49",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Novas features a partir das existentes\n",
    "\n",
    "df_teste = df_2.copy()\n",
    "\n",
    "df_teste['BaLim_ratio'] = df_teste['RevolvingUtilizationOfUnsecuredLines'].clip(upper=1.2)\n",
    "\n",
    "df_teste['age_2'] = np.where(df_teste['age'] == 0, 20, df_teste['age'])\n",
    "\n",
    "income_capped = df_teste['MonthlyIncome'].clip(upper=23300)\n",
    "# Depois, aplicamos a transformação de log\n",
    "df_teste['Income_log'] = np.log(income_capped + 10)\n",
    "        \n",
    "df_teste['Income_bool'] = np.where(df_teste['MonthlyIncome'] > 0, 1, 0)\n",
    "\n",
    "df_teste['Dep'] = df_teste['NumberOfDependents'].clip(upper=2)\n",
    "\n",
    "df_teste['D_Ratio'] = np.where(df_teste['DebtRatio'] >= 1200, 6, np.where(df_teste['DebtRatio'] > 4, 5, df_teste['DebtRatio']))\n",
    "        \n",
    "df_teste['OCLAL'] = np.log1p(df_teste['NumberOfOpenCreditLinesAndLoans'])\n",
    "\n",
    "df_teste['REOL'] = df_teste['NumberRealEstateLoansOrLines'].clip(upper=5)\n",
    "\n",
    "df_teste['Num_30-59'] = df_teste['NumberOfTime30-59DaysPastDueNotWorse'].clip(upper=3)\n",
    "\n",
    "df_teste['Num_60-89'] = df_teste['NumberOfTime60-89DaysPastDueNotWorse'].clip(upper=2)\n",
    "\n",
    "df_teste['Num_90'] = df_teste['NumberOfTimes90DaysLate'].clip(upper=2)\n",
    "\n",
    "df_teste['Income_log_sq'] = df_teste['Income_log']**2\n",
    "df_teste['Income_log_cub'] = df_teste['Income_log']**3\n",
    "df_teste['D_Ratio_sq'] = df_teste['D_Ratio']**2 \n",
    "\n",
    "\n",
    "df_teste_final = df_teste.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a91e9727-896e-4cae-8790-71e4ff2680a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "y = df_train['SeriousDlqin2yrs']\n",
    "X = df_train.drop(['SeriousDlqin2yrs','age','DebtRatio','MonthlyIncome','Unnamed: 0', 'NumberOfDependents','RevolvingUtilizationOfUnsecuredLines','NumberOfOpenCreditLinesAndLoans', 'NumberRealEstateLoansOrLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate'\n",
    "], axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(\"Formato dos dados de treino:\", y_train.mean())\n",
    "print(\"Formato dos dados de teste:\", y_test.mean())\n",
    "\n",
    "#X_train_eng = X_train.copy()\n",
    "#X_test_eng = X_test.copy()\n",
    "X_train.columns\n",
    "\n",
    "X_train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4e73fa19-e398-45fe-b7fd-723a290e6e05",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "model = xgb.XGBClassifier(\n",
    "    objective='binary:logistic',\n",
    "    eval_metric='auc',\n",
    "    use_label_encoder=False,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    \n",
    ")\n",
    "\n",
    "# Pipeline\n",
    "\n",
    "pipeline_final = ImbPipeline([\n",
    "    #('preprocessamento', preprocessor),\n",
    "    #('sampler', SMOTE(random_state=42, sampling_strategy=1)),\n",
    "    ('classificador', model)\n",
    "])\n",
    "\n",
    "\n",
    "# Parametros\n",
    "# Grid para RandomForest\n",
    "\n",
    "param_grid_rf = {\n",
    "    'classificador': [RandomForestClassifier(random_state=42, n_jobs=-1)], # Define o modelo a ser usado\n",
    "    'classificador__n_estimators': [200, 400],\n",
    "    'classificador__max_depth': [5, 10, 15],\n",
    "    'classificador__min_samples_leaf': [10, 20]\n",
    "}\n",
    "\n",
    "# Grid para XGBoost\n",
    "param_grid_xgb = {\n",
    "    # Tente aumentar o peso da classe minoritária ainda mais\n",
    "    'classificador__learning_rate': [0.03], # 'eta' do R\n",
    "    'classificador__max_depth': [4],\n",
    "    'classificador__n_estimators': [1000],   # 'nrounds' do R\n",
    "    'classificador__subsample': [0.5],\n",
    "    'classificador__colsample_bytree': [0.5]\n",
    "}\n",
    "\n",
    "# Grid para LightGBM\n",
    "param_grid_lgbm = {\n",
    "    'classificador': [lgb.LGBMClassifier(objective='binary', metric='auc', random_state=42, n_jobs=-1)],\n",
    "    'classificador__n_estimators': [500, 1000],\n",
    "    'classificador__learning_rate': [0.03],\n",
    "    'classificador__num_leaves': [20, 31, 40]\n",
    "}\n",
    "\n",
    "#Lista \n",
    "param_grid_completo = [param_grid_rf, param_grid_xgb, param_grid_lgbm]\n",
    "\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model, # <-- Usa o pipeline_final que acabamos de criar\n",
    "    param_grid=param_grid_completo,\n",
    "    scoring='roc_auc',\n",
    "    cv=5,\n",
    "    verbose=2,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Pré-processamento concluído com sucesso!\")\n",
    "#print(\"Formato dos dados de treino processados:\", X_train_transf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8129702a-78da-4d48-a33b-d4f99ceb7b3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- 5. Analise os Resultados ---\n",
    "\n",
    "print(\"\\nBusca concluída!\")\n",
    "print(\"\\nMelhor score AUC encontrado na validação cruzada:\")\n",
    "print(f\"{grid_search.best_score_:.4f}\")\n",
    "\n",
    "print(\"\\nMelhor combinação de modelo e parâmetros encontrada:\")\n",
    "# O .best_params_ agora te dirá qual 'classificador' foi o melhor!\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# Guarde o melhor pipeline completo encontrado\n",
    "melhor_modelo = grid_search.best_estimator_\n",
    "\n",
    "\n",
    "# --- 6. Avalie o Campeão no seu Conjunto de Teste Local ---\n",
    "y_pred = melhor_modelo.predict(X_test)\n",
    "y_pred_proba = melhor_modelo.predict_proba(X_test)[:, 1]\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"AVALIAÇÃO DO MELHOR MODELO ENCONTRADO\")\n",
    "print(\"=\"*40)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f\"\\nAUC Score no teste: {roc_auc_score(y_test, y_pred_proba):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fbfb1bc-4835-416f-9682-709d5074732d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Treinando com 100% do dataset\n",
    "y_treino_total = df_treino_final['SeriousDlqin2yrs']\n",
    "X_treino_total = df_treino_final.drop(['SeriousDlqin2yrs','age','DebtRatio','MonthlyIncome','Unnamed: 0', 'NumberOfDependents','RevolvingUtilizationOfUnsecuredLines','NumberOfOpenCreditLinesAndLoans', 'NumberRealEstateLoansOrLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate'\n",
    "], axis=1)\n",
    "\n",
    "# Definindo o conjunto teste com 100% dos dados.\n",
    "\n",
    "X_teste_total = df_teste_final.drop(['SeriousDlqin2yrs','age','DebtRatio','MonthlyIncome','Unnamed: 0', 'NumberOfDependents','RevolvingUtilizationOfUnsecuredLines','NumberOfOpenCreditLinesAndLoans', 'NumberRealEstateLoansOrLines', 'NumberOfTime30-59DaysPastDueNotWorse', 'NumberOfTime60-89DaysPastDueNotWorse','NumberOfTimes90DaysLate'\n",
    "], axis=1)\n",
    "\n",
    "\n",
    "#grid_search.fit(X_treino_total, y_treino_total)\n",
    "#previsoes_finais_proba = grid_search.predict_proba(X_teste_total)[:, 1]\n",
    "\n",
    "previsoes_finais_proba = melhor_modelo.predict_proba(X_teste_total)[:, 1]\n",
    "\n",
    "#previsoes_finais_proba = grid_search.predict_proba(X_teste_total)[:, 1]\n",
    "\n",
    "df_submissao = pd.DataFrame({\n",
    "    'Id': range(1, len(previsoes_finais_proba) + 1),\n",
    "    'Probability': previsoes_finais_proba\n",
    "})\n",
    "\n",
    "df_submissao['Probability'] = previsoes_finais_proba\n",
    "\n",
    "print(\"\\n--- ESTATÍSTICAS DAS PROBABILIDADES PREVISTAS ---\")\n",
    "print(df_submissao['Probability'].describe())"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Predict Churn",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
